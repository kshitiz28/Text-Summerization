{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeeqiqGBIzAV",
        "outputId": "645db92f-fe6b-42e7-eca9-22114c19c6c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/MyDrive/Colab Notebooks/abs_summ')"
      ],
      "metadata": {
        "id": "zIJ8clsKNbZF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ERUXFWU9dKMI",
        "outputId": "039821ee-fb1a-4706-fe26-3af376df78d3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trax\n",
            "  Downloading trax-1.4.1-py2.py3-none-any.whl (637 kB)\n",
            "\u001b[K     |████████████████████████████████| 637 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from trax) (1.7.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from trax) (1.3.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from trax) (4.6.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from trax) (0.5.0)\n",
            "Collecting funcsigs\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (from trax) (0.25.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.8/dist-packages (from trax) (0.3.25+cuda11.cudnn805)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from trax) (5.4.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from trax) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from trax) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from trax) (1.21.6)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.8/dist-packages (from trax) (0.3.25)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym->trax) (5.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym->trax) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym->trax) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym->trax) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from jax->trax) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax->trax) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->trax) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->trax) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->trax) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->trax) (3.0.9)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (4.64.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (0.3.6)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (0.10.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (5.10.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (2.23.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (2.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.0.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.57.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text->trax) (0.12.0)\n",
            "Collecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (14.0.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.28.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.51.1)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 43.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.14.1)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 42.0 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 47.9 MB/s \n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text, funcsigs, trax\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.12.6 funcsigs-1.0.2 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0 trax-1.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import trax\n",
        "from trax import layers as tl2"
      ],
      "metadata": {
        "id": "xaGBgURLdyNl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle\n",
        "from tensorflow.keras import layers as tl\n",
        "\n"
      ],
      "metadata": {
        "id": "FM316cyWMvBG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = pd.read_csv(\"drive/My Drive/Colab Notebooks/abs_summ/data/train.csv\")"
      ],
      "metadata": {
        "id": "4TXNlY_iI1iJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.drop(['id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "E6-3E2iTI7FA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1DDwIZiNI8zg",
        "outputId": "3f76415e-12fe-4595-9825-e848f995019b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             article  \\\n",
              "0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
              "1  (CNN) -- Ralph Mata was an internal affairs li...   \n",
              "2  A drunk driver who killed a young woman in a h...   \n",
              "3  (CNN) -- With a breezy sweep of his pen Presid...   \n",
              "4  Fleetwood are the only team still to have a 10...   \n",
              "\n",
              "                                          highlights  \n",
              "0  Bishop John Folda, of North Dakota, is taking ...  \n",
              "1  Criminal complaint: Cop used his role to help ...  \n",
              "2  Craig Eccleston-Todd, 27, had drunk at least t...  \n",
              "3  Nina dos Santos says Europe must be ready to a...  \n",
              "4  Fleetwood top of League One after 2-0 win at S...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c9f1129-3302-475e-86e0-6d49bb382107\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
              "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
              "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A drunk driver who killed a young woman in a h...</td>\n",
              "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n",
              "      <td>Nina dos Santos says Europe must be ready to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fleetwood are the only team still to have a 10...</td>\n",
              "      <td>Fleetwood top of League One after 2-0 win at S...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c9f1129-3302-475e-86e0-6d49bb382107')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c9f1129-3302-475e-86e0-6d49bb382107 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c9f1129-3302-475e-86e0-6d49bb382107');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAzGoLpDJCrO",
        "outputId": "3cf4c73a-0744-469a-905e-0b75008310c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(287113, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document = cnn['article']\n",
        "summary = cnn['highlights']"
      ],
      "metadata": {
        "id": "IGrXxBzwJH9A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document[30], summary[30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X7amTz3JI32",
        "outputId": "49d6bc48-c461-4347-bccc-cacd9288c7a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('By . Harriet Arkell For Mailonline . A pair of friends who dreamt up Marmite-themed board games during drunken dinners together have told how they won £50,000 backing from the Dragons\\' Den investment show. Father of two Richard McLuckie, 48, and his friend Stuart Mackenzie-Walker, 51, dreamt up a series of board games including Love It Or Hate It and Who Put The Marmite In The Fridge, over long evenings spent playing games and drinking wine. They won permission to use the name Marmite from brand owner, Unilever, before going onto Dragons\\' Den to ask for funding. But the pair, who have been friends since childhood when they lived across a glen from each other in Argyll, nearly lost their chance when they weren\\'t allowed to mention the name Marmite to the inquisitive Dragons. Scroll down for video . The friends came up with the idea of Marmite-themed board games - and persuaded the Dragons to invest . Dragons Duncan Bannatyne, second left, and Peter Jones, second right, put up £50,000 for the board games . Mr McLuckie, a former property developer who lives near Avignon, France, with his French wife, Betty, 43, and their daughters Clara, 15, and Esmee, 13, said: \\'Unilever had agreed to the licensing contract but told us we couldn\\'t mention Marmite on the show as they hadn\\'t yet agreed the design of the game. \\'They didn\\'t want any mention of it til it was signed off, so we were worried the Dragons wouldn\\'t be interested.\\' Three Dragons took their money off the table early, leaving Duncan Bannatyne and Peter Jones demanding to know more. Mr McLuckie said: \\'We told them we couldn\\'t say the name but it was an iconic brand and a well-known supermarket brand. \\'Eventually they demanded to see paperwork and when we showed it to them, Peter Jones said \"Oh it\\'s Marmite\", and they agreed to invest. Jones and Bannatyne said they would buy a 40 per cent stake in the men\\'s games start-up, Pants On Fire, and the games will go on sale next month. Love It Or Hate It, the title of which is based on the idea that Marmite provokes strong reactions one way or the other, is a game in which couples and friends can find out how much they know about each other. Inventor and board games enthusiast Richard McLuckie, 48, with some of the games he has dreamed up . The idea for Who Put The Marmite In The Fridge came to Mr McLuckie when he realised that his French wife was putting the Marmite in the fridge, meaning it was unspreadable on his toast every morning. He said: \\'My wife always puts it in the fridge which makes it like concrete, and now my children do the same thing, and every morning I ask the same thing. \\'It occurred to me it would be a great name for a board game.\\' He and Mr Mackenzie-Walker developed their ideas for games in a series of dinners over the years, but only decided to launch their business in 2009 after the property market crashed and Mr McLuckie needed a new job. First they came up with Liar Liar, in which players try to persuade their opponents to believe made-up facts, and Eurobabble, a modern version of Chinese Whispers in which players translate from one language to another and another. In Who Put The Marmite In The Fridge, players have to avoid being left with the jar of Marmite. Mr McLuckie and his childhood friend Mr Mackenzie-Walker, right, spent many nights playing board games . Mr McLuckie and Mr Mackenzie-Walker, an accountant by trade who moved from Kent to southern Spain, have now had their games snapped up by shops including John Lewis, WH Smith, Waterstones and Amazon. They appeared on Dragons\\' Den last night, and said their preconceptions about the Dragons were shattered after meeting them. \\'We thought we\\'d really like Piers Linney and Kelly Hoppen but in fact we thought Piers was quite dull and Kelly was a little bit rude and dismissive,\\' Mr McLuckie said. \\'Deborah Meaden was a surprise, as we thought she would be hard-nosed when in fact she was absolutely delightful - so lovely. \\'We thought Peter Jones would be fun, which he was, and we thought Duncan Bannatyne would be a hard task-master, when in fact he was lovely - we are so pleased to be working with those two. \\'They\\'re both great to work with and a really good laugh, too.\\'',\n",
              " \"Richard McLuckie, 48, and Stuart Mackenzie-Walker, 51, invented games .\\nWon permission from Marmite owner Unilever to use its name and image .\\nThen they went on investment TV show to ask for funding from the Dragons .\\nBut Unilever contract said entrepreneurs couldn't mention name Marmite .\\nThree Dragons pulled out, but Peter Jones and Duncan Bannatyne agreed .\\nThey paid the men £50,000 for a 40 per cent stake in board game business .\")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # for decoder sequence\n",
        "# summary = summary.apply(lambda x: '<go> ' + x + ' <stop>')\n",
        "# summary.head()"
      ],
      "metadata": {
        "id": "CVNKR_N4JLPo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since < and > from default tokens cannot be removed\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'"
      ],
      "metadata": {
        "id": "cnIm6y8kKGyI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)"
      ],
      "metadata": {
        "id": "BkhMBvE_J_9F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_tokenizer.fit_on_texts(document)\n",
        "summary_tokenizer.fit_on_texts(summary)"
      ],
      "metadata": {
        "id": "EpBPtpgrKDfD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = document_tokenizer.texts_to_sequences(document)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "metadata": {
        "id": "JzrhpIV4KKIX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.texts_to_sequences([\"This is a test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EupEbrXaKNt4",
        "outputId": "c75dd8c2-17c4-4bb8-a639-b9248825407f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[54, 11, 6, 549]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.sequences_to_texts([[54, 11, 6, 549]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs5MWD5mKQkE",
        "outputId": "4684cc42-1351-4883-83d5-8950d40d04ea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is a test']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "# vocab_size\n",
        "encoder_vocab_size, decoder_vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzYSoZXqKTCe",
        "outputId": "3dc7e755-31f1-470f-dbfb-79934835552b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(785451, 230198)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_lengths = pd.Series([len(x) for x in document])\n",
        "summary_lengths = pd.Series([len(x) for x in summary])"
      ],
      "metadata": {
        "id": "Ujc1NcjZKY3Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_lengths.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pzmsn-CKbQM",
        "outputId": "7dbbbfc9-302c-4f6c-c57d-895d4dd4936f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    287113.000000\n",
              "mean       4033.660865\n",
              "std        1954.339234\n",
              "min          48.000000\n",
              "25%        2583.000000\n",
              "50%        3682.000000\n",
              "75%        5117.000000\n",
              "max       15925.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_lengths.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKKC4gbaKdUr",
        "outputId": "d828edec-c50f-42c3-ba9c-22750762e699"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    287113.000000\n",
              "mean        294.770390\n",
              "std         120.197405\n",
              "min          14.000000\n",
              "25%         218.000000\n",
              "50%         280.000000\n",
              "75%         342.000000\n",
              "max        7388.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(input_str, EOS=1):\n",
        "    inputs=summary_tokenizer.texts_to_sequences([input_str])\n",
        "    # Mark the end of the sentence with EOS\n",
        "    input_list=inputs[0]\n",
        "    input_list.append(EOS)\n",
        "    return input_list\n",
        "\n",
        "def detokenize(integers):\n",
        "    \"\"\"List of ints to str\"\"\"\n",
        "  \n",
        "    s = summary_tokenizer.sequences_to_texts(integers)\n",
        "    \n",
        "    return s[0]"
      ],
      "metadata": {
        "id": "h3OvsEsLKhLC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize('This is a test')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys4PNZsfMk3Y",
        "outputId": "7113acc1-75ea-469f-94fe-356b56a7059b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[54, 11, 6, 549, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detokenize([[54, 11, 6, 549,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yUJ3HM9AP4bq",
        "outputId": "5b2662b8-d6e7-4fdd-dd04-d8ea24243638"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is a test <unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow._api.v2.experimental.numpy import int32\n",
        "def create_tensor(t):\n",
        "    \"\"\"Create tensor from list of lists\"\"\"\n",
        "    return tf.constant(t)\n",
        "    # if isinstance(t[0][0],bool):\n",
        "    #   return tf.constant(t)\n",
        "    # else:\n",
        "    #   return tf.constant(t,dtype=tf.float32)\n",
        "\n",
        "\n",
        "def display_tensor(t, name):\n",
        "    \"\"\"Display shape and tensor\"\"\"\n",
        "    print(f'{name} shape: {t.shape}\\n')\n",
        "    print(f'{t}\\n')"
      ],
      "metadata": {
        "id": "H0Bwuo6gV5g3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow._api.v2.experimental.numpy import int32\n",
        "def create_tensor(t):\n",
        "    \"\"\"Create tensor from list of lists\"\"\"\n",
        "    # return np.array(t)\n",
        "    if isinstance(t[0][0],bool):\n",
        "      return np.array(t)\n",
        "    else:\n",
        "      return np.array(t,dtype=np.float32)\n",
        "\n",
        "\n",
        "def display_tensor(t, name):\n",
        "    \"\"\"Display shape and tensor\"\"\"\n",
        "    print(f'{name} shape: {t.shape}\\n')\n",
        "    print(f'{t}\\n')"
      ],
      "metadata": {
        "id": "m2S88NYkyU_p"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = create_tensor([[1, 0, 0], [0, 1, 0]])\n",
        "display_tensor(q, 'query')\n",
        "k = create_tensor([[1, 2, 3], [4, 5, 6]])\n",
        "display_tensor(k, 'key')\n",
        "v = create_tensor([[0, 1, 0], [1, 0, 1]])\n",
        "display_tensor(v, 'value')\n",
        "m = create_tensor([[0, 0], [-1e9, 0]])\n",
        "display_tensor(m, 'mask')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTIYCZx4V6ef",
        "outputId": "04058235-f327-417d-90ad-96140b5195b9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query shape: (2, 3)\n",
            "\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]]\n",
            "\n",
            "key shape: (2, 3)\n",
            "\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "\n",
            "value shape: (2, 3)\n",
            "\n",
            "[[0. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "\n",
            "mask shape: (2, 2)\n",
            "\n",
            "[[ 0.e+00  0.e+00]\n",
            " [-1.e+09  0.e+00]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLdtdjVZX3ud",
        "outputId": "cb0d628f-29f8-4292-c298-c5edd83a262c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7320508075688772"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()"
      ],
      "metadata": {
        "id": "eSSxdq01ZBpv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_dot_k = np.dot(q,k.T) / np.sqrt(3)\n",
        "display_tensor(q_dot_k, 'query dot key')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpsxZZIYXDy9",
        "outputId": "7ee3a234-762a-4f2c-ed94-e486815045fe"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query dot key shape: (2, 2)\n",
            "\n",
            "[[0.57735026 2.309401  ]\n",
            " [1.1547005  2.8867514 ]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked = q_dot_k + m\n",
        "display_tensor(masked, 'masked query dot key')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA3-MFaHZGy3",
        "outputId": "f38a5d8f-f5e2-47ec-dda2-f726dfc7a3de"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "masked query dot key shape: (2, 2)\n",
            "\n",
            "[[ 5.7735026e-01  2.3094010e+00]\n",
            " [-1.0000000e+09  2.8867514e+00]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_tensor(masked @ v, 'masked query dot key dot value')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWOqUV58ZJ1_",
        "outputId": "37c7ef04-3d4c-48ae-e742-b771370579c1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "masked query dot key dot value shape: (2, 3)\n",
            "\n",
            "[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n",
            " [ 2.8867514e+00 -1.0000000e+09  2.8867514e+00]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_with_batch = q[None,:]\n",
        "display_tensor(q_with_batch, 'query with batch dim')\n",
        "k_with_batch = k[None,:]\n",
        "display_tensor(k_with_batch, 'key with batch dim')\n",
        "v_with_batch = v[None,:]\n",
        "display_tensor(v_with_batch, 'value with batch dim')\n",
        "m_bool = create_tensor([[True, True], [False, True]])\n",
        "display_tensor(m_bool, 'boolean mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZTHJHDfZNzv",
        "outputId": "b8607798-a794-4a1d-968b-df9a55a2f4a9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query with batch dim shape: (1, 2, 3)\n",
            "\n",
            "[[[1. 0. 0.]\n",
            "  [0. 1. 0.]]]\n",
            "\n",
            "key with batch dim shape: (1, 2, 3)\n",
            "\n",
            "[[[1. 2. 3.]\n",
            "  [4. 5. 6.]]]\n",
            "\n",
            "value with batch dim shape: (1, 2, 3)\n",
            "\n",
            "[[[0. 1. 0.]\n",
            "  [1. 0. 1.]]]\n",
            "\n",
            "boolean mask shape: (2, 2)\n",
            "\n",
            "[[ True  True]\n",
            " [False  True]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C1\n",
        "# GRADED FUNCTION: DotProductAttention\n",
        "def DotProductAttention(query, key, value, mask):\n",
        "    \"\"\"Dot product self-attention.\n",
        "    Args:\n",
        "        query (jax.interpreters.xla.DeviceArray): array of query representations with shape (L_q by d)\n",
        "        key (jax.interpreters.xla.DeviceArray): array of key representations with shape (L_k by d)\n",
        "        value (jax.interpreters.xla.DeviceArray): array of value representations with shape (L_k by d) where L_v = L_k\n",
        "        mask (jax.interpreters.xla.DeviceArray): attention-mask, gates attention with shape (L_q by L_k)\n",
        "\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: Self-attention array for q, k, v arrays. (L_q by L_k)\n",
        "    \"\"\"\n",
        "\n",
        "    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"Embedding dimensions of q, k, v aren't all the same\"\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
        "    # Save depth/dimension of the query embedding for scaling down the dot product\n",
        "    depth = query.shape[-1]\n",
        "\n",
        "    # Calculate scaled query key dot product according to formula above\n",
        "    dots = tf.linalg.matmul(query, tf.experimental.numpy.swapaxes(key, -1, -2)) / np.sqrt(depth)\n",
        "    \n",
        "    # Apply the mask\n",
        "    if mask is not None: # You do not need to replace the 'None' on this line\n",
        "        dots = tf.where(mask, dots, tf.experimental.numpy.full_like(dots, -1e9))\n",
        "    \n",
        "    # Softmax formula implementation\n",
        "    # Use trax.fastmath.logsumexp of masked_qkT to avoid underflow by division by large numbers\n",
        "    # Note: softmax = None\n",
        "    logsumexp = tf.math.reduce_logsumexp(dots, axis=-1, keepdims=True)\n",
        "\n",
        "    # Take exponential of dots minus logsumexp to get softmax\n",
        "    # Use jnp.exp()\n",
        "    dots = tf.math.exp(dots - logsumexp)\n",
        "    \n",
        "    # Multiply dots by value to get self-attention\n",
        "    # Use jnp.matmul()\n",
        "    attention = tf.linalg.matmul(dots, value)\n",
        "\n",
        "    ## END CODE HERE ###\n",
        "    \n",
        "    return attention"
      ],
      "metadata": {
        "id": "amfmZ8O1ZQeQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DotProductAttention(q_with_batch, k_with_batch, v_with_batch, m_bool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeK4xP8WZTpL",
        "outputId": "f060fc7d-7855-4e3b-e6bc-dd6a337e9a95"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 3), dtype=float32, numpy=\n",
              "array([[[0.8496746 , 0.15032545, 0.8496746 ],\n",
              "        [1.        , 0.        , 1.        ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d = create_tensor(q)\n",
        "display_tensor(tensor2d, 'query matrix (2D tensor)')\n",
        "\n",
        "tensor4d2b = create_tensor([[q, q], [q, q]])\n",
        "display_tensor(tensor4d2b, 'batch of two (multi-head) collections of query matrices (4D tensor)')\n",
        "\n",
        "tensor3dc = create_tensor([tf.concat([q, q], axis = -1)])\n",
        "display_tensor(tensor3dc, 'one batch of concatenated heads of query matrices (3d tensor)')\n",
        "\n",
        "tensor3dc3b = create_tensor([tf.concat([q, q], axis = -1), tf.concat([q, q], axis = -1), tf.concat([q, q], axis = -1)])\n",
        "display_tensor(tensor3dc3b, 'three batches of concatenated heads of query matrices (3d tensor)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "metiYpwtlUJy",
        "outputId": "4263089c-3056-40ae-9fcb-a3a5e4acfc40"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query matrix (2D tensor) shape: (2, 3)\n",
            "\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]]\n",
            "\n",
            "batch of two (multi-head) collections of query matrices (4D tensor) shape: (2, 2, 2, 3)\n",
            "\n",
            "[[[[1. 0. 0.]\n",
            "   [0. 1. 0.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [0. 1. 0.]]]\n",
            "\n",
            "\n",
            " [[[1. 0. 0.]\n",
            "   [0. 1. 0.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [0. 1. 0.]]]]\n",
            "\n",
            "one batch of concatenated heads of query matrices (3d tensor) shape: (1, 2, 6)\n",
            "\n",
            "[[[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]]\n",
            "\n",
            "three batches of concatenated heads of query matrices (3d tensor) shape: (3, 2, 6)\n",
            "\n",
            "[[[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C2\n",
        "# GRADED FUNCTION: compute_attention_heads_closure\n",
        "def compute_attention_heads_closure(n_heads, d_head):\n",
        "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
        "    Args:\n",
        "        d_head (int):  dimensionality of heads\n",
        "        n_heads (int): number of attention heads\n",
        "    Returns:\n",
        "        function: compute_attention_heads function\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_attention_heads(x):\n",
        "        \"\"\" Compute the attention heads.\n",
        "        Args:\n",
        "            x (jax.interpreters.xla.DeviceArray): tensor with shape (n_batch, seqlen, n_heads X d_head).\n",
        "        Returns:\n",
        "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (n_batch X n_heads, seqlen, d_head).\n",
        "        \"\"\"\n",
        "        ### START CODE HERE ###\n",
        "        # (REPLACE INSTANCES OF 'None' WITH YOUR CODE)\n",
        "        \n",
        "        # Size of the x's batch dimension\n",
        "        batch_size = x.shape[0]\n",
        "        # Length of the sequence\n",
        "        # Should be size of x's first dimension without counting the batch dim\n",
        "        seqlen = x.shape[1]\n",
        "        # Reshape x using jnp.reshape()\n",
        "        # n_batch, seqlen, n_heads*d_head -> n_batch, seqlen, n_heads, d_head\n",
        "        x = tf.reshape(x, (batch_size, seqlen, n_heads, d_head))\n",
        "        # Transpose x using jnp.transpose()\n",
        "        # n_batch, seqlen, n_heads, d_head -> n_batch, n_heads, seqlen, d_head\n",
        "        # Note that the values within the tuple are the indexes of the dimensions of x and you must rearrange them\n",
        "        x = tf.transpose(x, (0, 2, 1, 3))\n",
        "        # Reshape x using jnp.reshape()\n",
        "        # n_batch, n_heads, seqlen, d_head -> n_batch*n_heads, seqlen, d_head\n",
        "        x = tf.reshape(x, (-1, seqlen, d_head))\n",
        "        \n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        return x\n",
        "    return compute_attention_heads"
      ],
      "metadata": {
        "id": "NGYf3e4cmzTI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_tensor(tensor3dc3b, \"input tensor\")\n",
        "result_cah = compute_attention_heads_closure(2,3)(tensor3dc3b)\n",
        "display_tensor(result_cah, \"output tensor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIu5nel4nKqE",
        "outputId": "1342e1d9-6cbe-4ae2-ede8-8520a4371c9b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor shape: (3, 2, 6)\n",
            "\n",
            "[[[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]]\n",
            "\n",
            "output tensor shape: (6, 2, 3)\n",
            "\n",
            "[[[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C3\n",
        "# GRADED FUNCTION: dot_product_self_attention\n",
        "def dot_product_self_attention(q, k, v):\n",
        "    \"\"\" Masked dot product self attention.\n",
        "    Args:\n",
        "        q (jax.interpreters.xla.DeviceArray): queries.\n",
        "        k (jax.interpreters.xla.DeviceArray): keys.\n",
        "        v (jax.interpreters.xla.DeviceArray): values.\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: masked dot product self attention tensor.\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # Hint: mask size should be equal to L_q. Remember that q has shape (batch_size, L_q, d)\n",
        "    mask_size = q.shape[-2]\n",
        "\n",
        "    # Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)\n",
        "    # Notice that 1's and 0's get casted to True/False by setting dtype to jnp.bool_\n",
        "    # Use jnp.tril() - Lower triangle of an array and jnp.ones()\n",
        "    mask = np.tril(tf.ones((1, mask_size, mask_size), dtype=tf.experimental.numpy.bool_), k=0)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return DotProductAttention(q, k, v, mask)"
      ],
      "metadata": {
        "id": "NiXZ9CFF0jHd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dot_product_self_attention(q_with_batch, k_with_batch, v_with_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3DIcm9a0lOT",
        "outputId": "117b90aa-289f-4e5e-fa03-c0b75dd5349a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 3), dtype=float32, numpy=\n",
              "array([[[0.        , 1.        , 0.        ],\n",
              "        [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C4\n",
        "# GRADED FUNCTION: compute_attention_output_closure\n",
        "def compute_attention_output_closure(n_heads, d_head):\n",
        "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
        "    Args:\n",
        "        d_head (int):  dimensionality of heads\n",
        "        n_heads (int): number of attention heads\n",
        "    Returns:\n",
        "        function: compute_attention_output function\n",
        "    \"\"\"\n",
        "    \n",
        "    def compute_attention_output(x):\n",
        "        \"\"\" Compute the attention output.\n",
        "        Args:\n",
        "            x (jax.interpreters.xla.DeviceArray): tensor with shape (n_batch X n_heads, seqlen, d_head).\n",
        "        Returns:\n",
        "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (n_batch, seqlen, n_heads X d_head).\n",
        "        \"\"\"\n",
        "        ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
        "        \n",
        "        # Length of the sequence\n",
        "        # Should be size of x's first dimension without counting the batch dim\n",
        "        seqlen = x.shape[1]\n",
        "        # Reshape x using jnp.reshape() to shape (n_batch, n_heads, seqlen, d_head)\n",
        "        x = tf.reshape(x, ( -1, n_heads, seqlen, d_head))\n",
        "        # Transpose x using jnp.transpose() to shape (n_batch, seqlen, n_heads, d_head)\n",
        "        x = tf.transpose(x, ( 0, 2, 1 , 3))\n",
        "        \n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Reshape to allow to concatenate the heads\n",
        "        return tf.reshape(x, (-1, seqlen, n_heads * d_head))\n",
        "    return compute_attention_output"
      ],
      "metadata": {
        "id": "E5oLjfSe4s18"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_tensor(result_cah, \"input tensor\")\n",
        "result_cao = compute_attention_output_closure(2,3)(result_cah)\n",
        "display_tensor(result_cao, \"output tensor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqk24Qee46Ql",
        "outputId": "9cb871a7-1305-4590-9fd1-1395c892d281"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor shape: (6, 2, 3)\n",
            "\n",
            "[[[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]]\n",
            "\n",
            "output tensor shape: (3, 2, 6)\n",
            "\n",
            "[[[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C5\n",
        "# GRADED FUNCTION: CausalAttention\n",
        "def CausalAttention(d_feature, \n",
        "                    n_heads, \n",
        "                    compute_attention_heads_closure=compute_attention_heads_closure,\n",
        "                    dot_product_self_attention=dot_product_self_attention,\n",
        "                    compute_attention_output_closure=compute_attention_output_closure,\n",
        "                    mode='train'):\n",
        "    \"\"\"Transformer-style multi-headed causal attention.\n",
        "\n",
        "    Args:\n",
        "        d_feature (int):  dimensionality of feature embedding.\n",
        "        n_heads (int): number of attention heads.\n",
        "        compute_attention_heads_closure (function): Closure around compute_attention heads.\n",
        "        dot_product_self_attention (function): dot_product_self_attention function. \n",
        "        compute_attention_output_closure (function): Closure around compute_attention_output. \n",
        "        mode (str): 'train' or 'eval'.\n",
        "\n",
        "    Returns:\n",
        "        trax.layers.combinators.Serial: Multi-headed self-attention model.\n",
        "    \"\"\"\n",
        "    \n",
        "    assert d_feature % n_heads == 0\n",
        "    d_head = d_feature // n_heads\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # (REPLACE INSTANCES OF 'None' WITH YOUR CODE)\n",
        "    \n",
        "    # HINT: The second argument to tl.Fn() is an uncalled function (without the parentheses)\n",
        "    # Since you are dealing with closures you might need to call the outer \n",
        "    # function with the correct parameters to get the actual uncalled function.\n",
        "    # use 'compute_attention_heads_closure'\n",
        "    ComputeAttentionHeads = tl2.Fn('AttnHeads', compute_attention_heads_closure(n_heads, d_head), n_out=1)\n",
        "    \n",
        "\n",
        "    return tl2.Serial(\n",
        "        tl2.Branch( # creates three towers for one input, takes activations and creates queries keys and values\n",
        "            [tl2.Dense(d_feature), ComputeAttentionHeads], # queries\n",
        "            [tl2.Dense(d_feature), ComputeAttentionHeads], # keys\n",
        "            [tl2.Dense(d_feature), ComputeAttentionHeads], # values\n",
        "        ),\n",
        "        \n",
        "        tl2.Fn('DotProductAttn', dot_product_self_attention, n_out=1), # takes QKV\n",
        "        # HINT: The second argument to tl.Fn() is an uncalled function\n",
        "        # Since you are dealing with closures you might need to call the outer \n",
        "        # function with the correct parameters to get the actual uncalled function.\n",
        "        tl2.Fn('AttnOutput', compute_attention_output_closure(n_heads, d_head), n_out=1), # to allow for parallel\n",
        "        tl2.Dense(d_feature) # Final dense layer\n",
        "    )\n",
        "\n",
        "    ### END CODE HERE ###"
      ],
      "metadata": {
        "id": "OJSRiFRi68SZ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the causal attention model\n",
        "print(CausalAttention(d_feature=512, n_heads=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFeri89r5SEn",
        "outputId": "2a2f80ff-4519-49fd-a03a-62cc38e41065"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serial[\n",
            "  Branch_out3[\n",
            "    [Dense_512, AttnHeads]\n",
            "    [Dense_512, AttnHeads]\n",
            "    [Dense_512, AttnHeads]\n",
            "  ]\n",
            "  DotProductAttn_in3\n",
            "  AttnOutput\n",
            "  Dense_512\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C6\n",
        "# GRADED FUNCTION: DecoderBlock\n",
        "def DecoderBlock(d_model, d_ff, n_heads,\n",
        "                 dropout, mode, ff_activation):\n",
        "    \"\"\"Returns a list of layers that implements a Transformer decoder block.\n",
        "\n",
        "    The input is an activation tensor.\n",
        "\n",
        "    Args:\n",
        "        d_model (int):  depth of embedding.\n",
        "        d_ff (int): depth of feed-forward layer.\n",
        "        n_heads (int): number of attention heads.\n",
        "        dropout (float): dropout rate (how much to drop out).\n",
        "        mode (str): 'train' or 'eval'.\n",
        "        ff_activation (function): the non-linearity in feed-forward layer.\n",
        "\n",
        "    Returns:\n",
        "        list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
        "    \n",
        "     # Create masked multi-head attention block using CausalAttention function\n",
        "    causal_attention = CausalAttention( \n",
        "                        d_model,\n",
        "                        n_heads=n_heads,\n",
        "                        mode=mode\n",
        "                        )\n",
        "\n",
        "    # Create feed-forward block (list) with two dense layers with dropout and input normalized\n",
        "    feed_forward = [ \n",
        "        # Normalize layer inputs\n",
        "        tl2.LayerNorm(),\n",
        "        # Add first feed forward (dense) layer (don't forget to set the correct value for n_units)\n",
        "        tl2.Dense(d_ff),\n",
        "        # Add activation function passed in as a parameter (you need to call it!)\n",
        "        ff_activation(), # Generally ReLU\n",
        "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
        "        tl2.Dropout(rate=dropout, mode=mode),\n",
        "        # Add second feed forward layer (don't forget to set the correct value for n_units)\n",
        "        tl2.Dense(d_model),\n",
        "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
        "        tl2.Dropout(rate=dropout, mode=mode)\n",
        "    ]\n",
        "\n",
        "    # Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks\n",
        "    return [\n",
        "      tl2.Residual(\n",
        "          # Normalize layer input\n",
        "          tl2.LayerNorm(),\n",
        "          # Add causal attention block previously defined (without parentheses)\n",
        "          causal_attention,\n",
        "          # Add dropout with rate and mode specified\n",
        "          tl2.Dropout(rate=dropout, mode=mode)\n",
        "        ),\n",
        "      tl2.Residual(\n",
        "          # Add feed forward block (without parentheses)\n",
        "          feed_forward\n",
        "        ),\n",
        "      ]\n",
        "    ### END CODE HERE ###"
      ],
      "metadata": {
        "id": "W0_Wz8BrgLuW"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the decoder block\n",
        "print(DecoderBlock(d_model=512, d_ff=2048, n_heads=8, dropout=0.1, mode='train', ff_activation=tl2.Relu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYWnGtVlggGZ",
        "outputId": "ba88b2b2-bb00-4758-de86-fc8a293570a0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Serial[\n",
            "  Branch_out2[\n",
            "    None\n",
            "    Serial[\n",
            "      LayerNorm\n",
            "      Serial[\n",
            "        Branch_out3[\n",
            "          [Dense_512, AttnHeads]\n",
            "          [Dense_512, AttnHeads]\n",
            "          [Dense_512, AttnHeads]\n",
            "        ]\n",
            "        DotProductAttn_in3\n",
            "        AttnOutput\n",
            "        Dense_512\n",
            "      ]\n",
            "      Dropout\n",
            "    ]\n",
            "  ]\n",
            "  Add_in2\n",
            "], Serial[\n",
            "  Branch_out2[\n",
            "    None\n",
            "    Serial[\n",
            "      LayerNorm\n",
            "      Dense_2048\n",
            "      Serial[\n",
            "        Relu\n",
            "      ]\n",
            "      Dropout\n",
            "      Dense_512\n",
            "      Dropout\n",
            "    ]\n",
            "  ]\n",
            "  Add_in2\n",
            "]]\n"
          ]
        }
      ]
    }
  ]
}