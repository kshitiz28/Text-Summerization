{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C_CSdH6VIWDa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle\n",
        "from tensorflow.keras import layers as tl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeeqiqGBIzAV",
        "outputId": "21a7c4dd-77d7-43c7-a179-1ddadd0f7f85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = pd.read_csv(\"drive/My Drive/Colab Notebooks/abs_summ/data/train.csv\")"
      ],
      "metadata": {
        "id": "4TXNlY_iI1iJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.drop(['id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "E6-3E2iTI7FA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1DDwIZiNI8zg",
        "outputId": "3dadd938-a909-4fed-fda7-14ca1a876941"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             article  \\\n",
              "0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
              "1  (CNN) -- Ralph Mata was an internal affairs li...   \n",
              "2  A drunk driver who killed a young woman in a h...   \n",
              "3  (CNN) -- With a breezy sweep of his pen Presid...   \n",
              "4  Fleetwood are the only team still to have a 10...   \n",
              "\n",
              "                                          highlights  \n",
              "0  Bishop John Folda, of North Dakota, is taking ...  \n",
              "1  Criminal complaint: Cop used his role to help ...  \n",
              "2  Craig Eccleston-Todd, 27, had drunk at least t...  \n",
              "3  Nina dos Santos says Europe must be ready to a...  \n",
              "4  Fleetwood top of League One after 2-0 win at S...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21514c4f-1f40-4681-9a60-94554bfd148f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
              "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
              "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A drunk driver who killed a young woman in a h...</td>\n",
              "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n",
              "      <td>Nina dos Santos says Europe must be ready to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fleetwood are the only team still to have a 10...</td>\n",
              "      <td>Fleetwood top of League One after 2-0 win at S...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21514c4f-1f40-4681-9a60-94554bfd148f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21514c4f-1f40-4681-9a60-94554bfd148f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21514c4f-1f40-4681-9a60-94554bfd148f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAzGoLpDJCrO",
        "outputId": "0465d258-4edc-404e-8a43-36b2fe215365"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(287113, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document = cnn['article']\n",
        "summary = cnn['highlights']"
      ],
      "metadata": {
        "id": "IGrXxBzwJH9A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document[30], summary[30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X7amTz3JI32",
        "outputId": "ea7432e6-a0d9-41d2-ad1a-a3d643486c33"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('By . Harriet Arkell For Mailonline . A pair of friends who dreamt up Marmite-themed board games during drunken dinners together have told how they won £50,000 backing from the Dragons\\' Den investment show. Father of two Richard McLuckie, 48, and his friend Stuart Mackenzie-Walker, 51, dreamt up a series of board games including Love It Or Hate It and Who Put The Marmite In The Fridge, over long evenings spent playing games and drinking wine. They won permission to use the name Marmite from brand owner, Unilever, before going onto Dragons\\' Den to ask for funding. But the pair, who have been friends since childhood when they lived across a glen from each other in Argyll, nearly lost their chance when they weren\\'t allowed to mention the name Marmite to the inquisitive Dragons. Scroll down for video . The friends came up with the idea of Marmite-themed board games - and persuaded the Dragons to invest . Dragons Duncan Bannatyne, second left, and Peter Jones, second right, put up £50,000 for the board games . Mr McLuckie, a former property developer who lives near Avignon, France, with his French wife, Betty, 43, and their daughters Clara, 15, and Esmee, 13, said: \\'Unilever had agreed to the licensing contract but told us we couldn\\'t mention Marmite on the show as they hadn\\'t yet agreed the design of the game. \\'They didn\\'t want any mention of it til it was signed off, so we were worried the Dragons wouldn\\'t be interested.\\' Three Dragons took their money off the table early, leaving Duncan Bannatyne and Peter Jones demanding to know more. Mr McLuckie said: \\'We told them we couldn\\'t say the name but it was an iconic brand and a well-known supermarket brand. \\'Eventually they demanded to see paperwork and when we showed it to them, Peter Jones said \"Oh it\\'s Marmite\", and they agreed to invest. Jones and Bannatyne said they would buy a 40 per cent stake in the men\\'s games start-up, Pants On Fire, and the games will go on sale next month. Love It Or Hate It, the title of which is based on the idea that Marmite provokes strong reactions one way or the other, is a game in which couples and friends can find out how much they know about each other. Inventor and board games enthusiast Richard McLuckie, 48, with some of the games he has dreamed up . The idea for Who Put The Marmite In The Fridge came to Mr McLuckie when he realised that his French wife was putting the Marmite in the fridge, meaning it was unspreadable on his toast every morning. He said: \\'My wife always puts it in the fridge which makes it like concrete, and now my children do the same thing, and every morning I ask the same thing. \\'It occurred to me it would be a great name for a board game.\\' He and Mr Mackenzie-Walker developed their ideas for games in a series of dinners over the years, but only decided to launch their business in 2009 after the property market crashed and Mr McLuckie needed a new job. First they came up with Liar Liar, in which players try to persuade their opponents to believe made-up facts, and Eurobabble, a modern version of Chinese Whispers in which players translate from one language to another and another. In Who Put The Marmite In The Fridge, players have to avoid being left with the jar of Marmite. Mr McLuckie and his childhood friend Mr Mackenzie-Walker, right, spent many nights playing board games . Mr McLuckie and Mr Mackenzie-Walker, an accountant by trade who moved from Kent to southern Spain, have now had their games snapped up by shops including John Lewis, WH Smith, Waterstones and Amazon. They appeared on Dragons\\' Den last night, and said their preconceptions about the Dragons were shattered after meeting them. \\'We thought we\\'d really like Piers Linney and Kelly Hoppen but in fact we thought Piers was quite dull and Kelly was a little bit rude and dismissive,\\' Mr McLuckie said. \\'Deborah Meaden was a surprise, as we thought she would be hard-nosed when in fact she was absolutely delightful - so lovely. \\'We thought Peter Jones would be fun, which he was, and we thought Duncan Bannatyne would be a hard task-master, when in fact he was lovely - we are so pleased to be working with those two. \\'They\\'re both great to work with and a really good laugh, too.\\'',\n",
              " \"Richard McLuckie, 48, and Stuart Mackenzie-Walker, 51, invented games .\\nWon permission from Marmite owner Unilever to use its name and image .\\nThen they went on investment TV show to ask for funding from the Dragons .\\nBut Unilever contract said entrepreneurs couldn't mention name Marmite .\\nThree Dragons pulled out, but Peter Jones and Duncan Bannatyne agreed .\\nThey paid the men £50,000 for a 40 per cent stake in board game business .\")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # for decoder sequence\n",
        "# summary = summary.apply(lambda x: '<go> ' + x + ' <stop>')\n",
        "# summary.head()"
      ],
      "metadata": {
        "id": "CVNKR_N4JLPo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since < and > from default tokens cannot be removed\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'"
      ],
      "metadata": {
        "id": "cnIm6y8kKGyI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)"
      ],
      "metadata": {
        "id": "BkhMBvE_J_9F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_tokenizer.fit_on_texts(document)\n",
        "summary_tokenizer.fit_on_texts(summary)"
      ],
      "metadata": {
        "id": "EpBPtpgrKDfD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = document_tokenizer.texts_to_sequences(document)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "metadata": {
        "id": "JzrhpIV4KKIX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.texts_to_sequences([\"This is a test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EupEbrXaKNt4",
        "outputId": "2ec642e0-bb7c-45e8-ad84-3090f89071aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[54, 11, 6, 549]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.sequences_to_texts([[54, 11, 6, 549]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs5MWD5mKQkE",
        "outputId": "d7f35e37-2dcf-4262-d34b-df1cc7fa8032"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is a test']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "# vocab_size\n",
        "encoder_vocab_size, decoder_vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzYSoZXqKTCe",
        "outputId": "1875ea0b-5cb6-42bd-83ac-1f4a7dcaf977"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(785451, 230198)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_lengths = pd.Series([len(x) for x in document])\n",
        "summary_lengths = pd.Series([len(x) for x in summary])"
      ],
      "metadata": {
        "id": "Ujc1NcjZKY3Q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_lengths.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pzmsn-CKbQM",
        "outputId": "ad5f1ee7-04a9-4824-c8a9-d19b868c9e57"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    287113.000000\n",
              "mean       4033.660865\n",
              "std        1954.339234\n",
              "min          48.000000\n",
              "25%        2583.000000\n",
              "50%        3682.000000\n",
              "75%        5117.000000\n",
              "max       15925.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_lengths.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKKC4gbaKdUr",
        "outputId": "8692a818-775f-490c-91fb-165477abb5d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    287113.000000\n",
              "mean        294.770390\n",
              "std         120.197405\n",
              "min          14.000000\n",
              "25%         218.000000\n",
              "50%         280.000000\n",
              "75%         342.000000\n",
              "max        7388.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(input_str, EOS=1):\n",
        "    inputs=summary_tokenizer.texts_to_sequences([input_str])\n",
        "    # Mark the end of the sentence with EOS\n",
        "    input_list=inputs[0]\n",
        "    input_list.append(EOS)\n",
        "    return input_list\n",
        "\n",
        "def detokenize(integers):\n",
        "    \"\"\"List of ints to str\"\"\"\n",
        "  \n",
        "    s = summary_tokenizer.sequences_to_texts(integers)\n",
        "    \n",
        "    return s[0]"
      ],
      "metadata": {
        "id": "h3OvsEsLKhLC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize('This is a test')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys4PNZsfMk3Y",
        "outputId": "537c25a4-8de8-4e51-cfe1-38dfc1298a32"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[54, 11, 6, 549, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detokenize([[54, 11, 6, 549,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yUJ3HM9AP4bq",
        "outputId": "6d6e71fa-3fe3-4ad2-fc6c-340e6fd51195"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is a test <unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow._api.v2.experimental.numpy import int32\n",
        "def create_tensor(t):\n",
        "    \"\"\"Create tensor from list of lists\"\"\"\n",
        "    return tf.constant(t)\n",
        "    # if isinstance(t[0][0],bool):\n",
        "    #   return tf.constant(t)\n",
        "    # else:\n",
        "    #   return tf.constant(t,dtype=tf.float32)\n",
        "\n",
        "\n",
        "def display_tensor(t, name):\n",
        "    \"\"\"Display shape and tensor\"\"\"\n",
        "    print(f'{name} shape: {t.shape}\\n')\n",
        "    print(f'{t}\\n')"
      ],
      "metadata": {
        "id": "H0Bwuo6gV5g3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow._api.v2.experimental.numpy import int32\n",
        "def create_tensor(t):\n",
        "    \"\"\"Create tensor from list of lists\"\"\"\n",
        "    # return np.array(t)\n",
        "    if isinstance(t[0][0],bool):\n",
        "      return np.array(t)\n",
        "    else:\n",
        "      return np.array(t,dtype=np.float32)\n",
        "\n",
        "\n",
        "def display_tensor(t, name):\n",
        "    \"\"\"Display shape and tensor\"\"\"\n",
        "    print(f'{name} shape: {t.shape}\\n')\n",
        "    print(f'{t}\\n')"
      ],
      "metadata": {
        "id": "m2S88NYkyU_p"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = create_tensor([[1, 0, 0], [0, 1, 0]])\n",
        "display_tensor(q, 'query')\n",
        "k = create_tensor([[1, 2, 3], [4, 5, 6]])\n",
        "display_tensor(k, 'key')\n",
        "v = create_tensor([[0, 1, 0], [1, 0, 1]])\n",
        "display_tensor(v, 'value')\n",
        "m = create_tensor([[0, 0], [-1e9, 0]])\n",
        "display_tensor(m, 'mask')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTIYCZx4V6ef",
        "outputId": "46f667de-112d-47c2-9b96-0fcfef3c63d5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query shape: (2, 3)\n",
            "\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]]\n",
            "\n",
            "key shape: (2, 3)\n",
            "\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "\n",
            "value shape: (2, 3)\n",
            "\n",
            "[[0. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "\n",
            "mask shape: (2, 2)\n",
            "\n",
            "[[ 0.e+00  0.e+00]\n",
            " [-1.e+09  0.e+00]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLdtdjVZX3ud",
        "outputId": "02237841-e41f-4ab4-b2dc-c6177f7109f4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7320508075688772"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()"
      ],
      "metadata": {
        "id": "eSSxdq01ZBpv"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_dot_k = np.dot(q,k.T) / np.sqrt(3)\n",
        "display_tensor(q_dot_k, 'query dot key')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpsxZZIYXDy9",
        "outputId": "b9591809-abf4-4a55-cd14-ca02d4770e86"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query dot key shape: (2, 2)\n",
            "\n",
            "[[0.57735026 2.309401  ]\n",
            " [1.1547005  2.8867514 ]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked = q_dot_k + m\n",
        "display_tensor(masked, 'masked query dot key')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA3-MFaHZGy3",
        "outputId": "f9d52601-a084-4b8f-a7f4-a4127f7baa4e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "masked query dot key shape: (2, 2)\n",
            "\n",
            "[[ 5.7735026e-01  2.3094010e+00]\n",
            " [-1.0000000e+09  2.8867514e+00]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_tensor(masked @ v, 'masked query dot key dot value')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWOqUV58ZJ1_",
        "outputId": "be03a3c2-e3e2-421e-ea37-6767e9bdc3a2"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "masked query dot key dot value shape: (2, 3)\n",
            "\n",
            "[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n",
            " [ 2.8867514e+00 -1.0000000e+09  2.8867514e+00]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_with_batch = q[None,:]\n",
        "display_tensor(q_with_batch, 'query with batch dim')\n",
        "k_with_batch = k[None,:]\n",
        "display_tensor(k_with_batch, 'key with batch dim')\n",
        "v_with_batch = v[None,:]\n",
        "display_tensor(v_with_batch, 'value with batch dim')\n",
        "m_bool = create_tensor([[True, True], [False, True]])\n",
        "display_tensor(m_bool, 'boolean mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZTHJHDfZNzv",
        "outputId": "5a16c022-eafa-4041-93aa-ddf50990fadf"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query with batch dim shape: (1, 2, 3)\n",
            "\n",
            "[[[1. 0. 0.]\n",
            "  [0. 1. 0.]]]\n",
            "\n",
            "key with batch dim shape: (1, 2, 3)\n",
            "\n",
            "[[[1. 2. 3.]\n",
            "  [4. 5. 6.]]]\n",
            "\n",
            "value with batch dim shape: (1, 2, 3)\n",
            "\n",
            "[[[0. 1. 0.]\n",
            "  [1. 0. 1.]]]\n",
            "\n",
            "boolean mask shape: (2, 2)\n",
            "\n",
            "[[ True  True]\n",
            " [False  True]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C1\n",
        "# GRADED FUNCTION: DotProductAttention\n",
        "def DotProductAttention(query, key, value, mask):\n",
        "    \"\"\"Dot product self-attention.\n",
        "    Args:\n",
        "        query (jax.interpreters.xla.DeviceArray): array of query representations with shape (L_q by d)\n",
        "        key (jax.interpreters.xla.DeviceArray): array of key representations with shape (L_k by d)\n",
        "        value (jax.interpreters.xla.DeviceArray): array of value representations with shape (L_k by d) where L_v = L_k\n",
        "        mask (jax.interpreters.xla.DeviceArray): attention-mask, gates attention with shape (L_q by L_k)\n",
        "\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: Self-attention array for q, k, v arrays. (L_q by L_k)\n",
        "    \"\"\"\n",
        "\n",
        "    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"Embedding dimensions of q, k, v aren't all the same\"\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
        "    # Save depth/dimension of the query embedding for scaling down the dot product\n",
        "    depth = query.shape[-1]\n",
        "\n",
        "    # Calculate scaled query key dot product according to formula above\n",
        "    dots = tf.linalg.matmul(query, tf.experimental.numpy.swapaxes(key, -1, -2)) / np.sqrt(depth)\n",
        "    \n",
        "    # Apply the mask\n",
        "    if mask is not None: # You do not need to replace the 'None' on this line\n",
        "        dots = tf.where(mask, dots, tf.experimental.numpy.full_like(dots, -1e9))\n",
        "    \n",
        "    # Softmax formula implementation\n",
        "    # Use trax.fastmath.logsumexp of masked_qkT to avoid underflow by division by large numbers\n",
        "    # Note: softmax = None\n",
        "    logsumexp = tf.math.reduce_logsumexp(dots, axis=-1, keepdims=True)\n",
        "\n",
        "    # Take exponential of dots minus logsumexp to get softmax\n",
        "    # Use jnp.exp()\n",
        "    dots = tf.math.exp(dots - logsumexp)\n",
        "    \n",
        "    # Multiply dots by value to get self-attention\n",
        "    # Use jnp.matmul()\n",
        "    attention = tf.linalg.matmul(dots, value)\n",
        "\n",
        "    ## END CODE HERE ###\n",
        "    \n",
        "    return attention"
      ],
      "metadata": {
        "id": "amfmZ8O1ZQeQ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DotProductAttention(q_with_batch, k_with_batch, v_with_batch, m_bool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeK4xP8WZTpL",
        "outputId": "6448f738-5c0a-4e12-8d6e-413a5cb0ed38"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 3), dtype=float32, numpy=\n",
              "array([[[0.8496746 , 0.15032545, 0.8496746 ],\n",
              "        [1.        , 0.        , 1.        ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d = create_tensor(q)\n",
        "display_tensor(tensor2d, 'query matrix (2D tensor)')\n",
        "\n",
        "tensor4d2b = create_tensor([[q, q], [q, q]])\n",
        "display_tensor(tensor4d2b, 'batch of two (multi-head) collections of query matrices (4D tensor)')\n",
        "\n",
        "tensor3dc = create_tensor([tf.concat([q, q], axis = -1)])\n",
        "display_tensor(tensor3dc, 'one batch of concatenated heads of query matrices (3d tensor)')\n",
        "\n",
        "tensor3dc3b = create_tensor([tf.concat([q, q], axis = -1), tf.concat([q, q], axis = -1), tf.concat([q, q], axis = -1)])\n",
        "display_tensor(tensor3dc3b, 'three batches of concatenated heads of query matrices (3d tensor)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "metiYpwtlUJy",
        "outputId": "1a36af2b-bd2a-4c97-8f1c-7ad4f1cd8d40"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query matrix (2D tensor) shape: (2, 3)\n",
            "\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]]\n",
            "\n",
            "batch of two (multi-head) collections of query matrices (4D tensor) shape: (2, 2, 2, 3)\n",
            "\n",
            "[[[[1. 0. 0.]\n",
            "   [0. 1. 0.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [0. 1. 0.]]]\n",
            "\n",
            "\n",
            " [[[1. 0. 0.]\n",
            "   [0. 1. 0.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [0. 1. 0.]]]]\n",
            "\n",
            "one batch of concatenated heads of query matrices (3d tensor) shape: (1, 2, 6)\n",
            "\n",
            "[[[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]]\n",
            "\n",
            "three batches of concatenated heads of query matrices (3d tensor) shape: (3, 2, 6)\n",
            "\n",
            "[[[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C2\n",
        "# GRADED FUNCTION: compute_attention_heads_closure\n",
        "def compute_attention_heads_closure(n_heads, d_head):\n",
        "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
        "    Args:\n",
        "        d_head (int):  dimensionality of heads\n",
        "        n_heads (int): number of attention heads\n",
        "    Returns:\n",
        "        function: compute_attention_heads function\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_attention_heads(x):\n",
        "        \"\"\" Compute the attention heads.\n",
        "        Args:\n",
        "            x (jax.interpreters.xla.DeviceArray): tensor with shape (n_batch, seqlen, n_heads X d_head).\n",
        "        Returns:\n",
        "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (n_batch X n_heads, seqlen, d_head).\n",
        "        \"\"\"\n",
        "        ### START CODE HERE ###\n",
        "        # (REPLACE INSTANCES OF 'None' WITH YOUR CODE)\n",
        "        \n",
        "        # Size of the x's batch dimension\n",
        "        batch_size = x.shape[0]\n",
        "        # Length of the sequence\n",
        "        # Should be size of x's first dimension without counting the batch dim\n",
        "        seqlen = x.shape[1]\n",
        "        # Reshape x using jnp.reshape()\n",
        "        # n_batch, seqlen, n_heads*d_head -> n_batch, seqlen, n_heads, d_head\n",
        "        x = tf.reshape(x, (batch_size, seqlen, n_heads, d_head))\n",
        "        # Transpose x using jnp.transpose()\n",
        "        # n_batch, seqlen, n_heads, d_head -> n_batch, n_heads, seqlen, d_head\n",
        "        # Note that the values within the tuple are the indexes of the dimensions of x and you must rearrange them\n",
        "        x = tf.transpose(x, (0, 2, 1, 3))\n",
        "        # Reshape x using jnp.reshape()\n",
        "        # n_batch, n_heads, seqlen, d_head -> n_batch*n_heads, seqlen, d_head\n",
        "        x = tf.reshape(x, (-1, seqlen, d_head))\n",
        "        \n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        return x\n",
        "    return compute_attention_heads"
      ],
      "metadata": {
        "id": "NGYf3e4cmzTI"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_tensor(tensor3dc3b, \"input tensor\")\n",
        "result_cah = compute_attention_heads_closure(2,3)(tensor3dc3b)\n",
        "display_tensor(result_cah, \"output tensor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIu5nel4nKqE",
        "outputId": "5c5f89fc-3ac7-408d-c74a-2561e4e5c165"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor shape: (3, 2, 6)\n",
            "\n",
            "[[[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 1. 0.]]]\n",
            "\n",
            "output tensor shape: (6, 2, 3)\n",
            "\n",
            "[[[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0.]\n",
            "  [0. 1. 0.]]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C3\n",
        "# GRADED FUNCTION: dot_product_self_attention\n",
        "def dot_product_self_attention(q, k, v):\n",
        "    \"\"\" Masked dot product self attention.\n",
        "    Args:\n",
        "        q (jax.interpreters.xla.DeviceArray): queries.\n",
        "        k (jax.interpreters.xla.DeviceArray): keys.\n",
        "        v (jax.interpreters.xla.DeviceArray): values.\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: masked dot product self attention tensor.\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # Hint: mask size should be equal to L_q. Remember that q has shape (batch_size, L_q, d)\n",
        "    mask_size = q.shape[-2]\n",
        "\n",
        "    # Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)\n",
        "    # Notice that 1's and 0's get casted to True/False by setting dtype to jnp.bool_\n",
        "    # Use jnp.tril() - Lower triangle of an array and jnp.ones()\n",
        "    mask = np.tril(tf.ones((1, mask_size, mask_size), dtype=tf.experimental.numpy.bool_), k=0)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return DotProductAttention(q, k, v, mask)"
      ],
      "metadata": {
        "id": "NiXZ9CFF0jHd"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dot_product_self_attention(q_with_batch, k_with_batch, v_with_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3DIcm9a0lOT",
        "outputId": "0f7dc1a2-a0e5-4964-e1f1-c11e2985e2e4"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 3), dtype=float32, numpy=\n",
              "array([[[0.        , 1.        , 0.        ],\n",
              "        [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # UNQ_C6\n",
        "# # GRADED FUNCTION: DecoderBlock\n",
        "# def DecoderBlock(d_model, d_ff, n_heads,\n",
        "#                  dropout, mode, ff_activation):\n",
        "#     \"\"\"Returns a list of layers that implements a Transformer decoder block.\n",
        "\n",
        "#     The input is an activation tensor.\n",
        "\n",
        "#     Args:\n",
        "#         d_model (int):  depth of embedding.\n",
        "#         d_ff (int): depth of feed-forward layer.\n",
        "#         n_heads (int): number of attention heads.\n",
        "#         dropout (float): dropout rate (how much to drop out).\n",
        "#         mode (str): 'train' or 'eval'.\n",
        "#         ff_activation (function): the non-linearity in feed-forward layer.\n",
        "\n",
        "#     Returns:\n",
        "#         list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.\n",
        "#     \"\"\"\n",
        "    \n",
        "#     ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
        "    \n",
        "#      # Create masked multi-head attention block using CausalAttention function\n",
        "#     causal_attention = CausalAttention( \n",
        "#                         d_model,\n",
        "#                         n_heads=n_heads,\n",
        "#                         mode=mode\n",
        "#                         )\n",
        "\n",
        "#     # Create feed-forward block (list) with two dense layers with dropout and input normalized\n",
        "#     feed_forward = [ \n",
        "#         # Normalize layer inputs\n",
        "#         tl.LayerNorm(),\n",
        "#         # Add first feed forward (dense) layer (don't forget to set the correct value for n_units)\n",
        "#         tl.Dense(d_ff),\n",
        "#         # Add activation function passed in as a parameter (you need to call it!)\n",
        "#         ff_activation(), # Generally ReLU\n",
        "#         # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
        "#         tl.Dropout(rate=dropout, mode=mode),\n",
        "#         # Add second feed forward layer (don't forget to set the correct value for n_units)\n",
        "#         tl.Dense(d_model),\n",
        "#         # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
        "#         tl.Dropout(rate=dropout, mode=mode)\n",
        "#     ]\n",
        "\n",
        "#     # Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks\n",
        "#     return [\n",
        "#       tl.Residual(\n",
        "#           # Normalize layer input\n",
        "#           tl.LayerNorm(),\n",
        "#           # Add causal attention block previously defined (without parentheses)\n",
        "#           causal_attention,\n",
        "#           # Add dropout with rate and mode specified\n",
        "#           tl.Dropout(rate=dropout, mode=mode)\n",
        "#         ),\n",
        "#       tl.Residual(\n",
        "#           # Add feed forward block (without parentheses)\n",
        "#           feed_forward\n",
        "#         ),\n",
        "#       ]\n",
        "#     ### END CODE HERE ###"
      ],
      "metadata": {
        "id": "DU-U4dS7Udyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Take a look at the decoder block\n",
        "# print(DecoderBlock(d_model=512, d_ff=2048, n_heads=8, dropout=0.1, mode='train', ff_activation=tl.Relu))"
      ],
      "metadata": {
        "id": "vGvHoFQ0UzSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}