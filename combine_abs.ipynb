{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_CSdH6VIWDa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle\n",
        "from tensorflow.keras import layers as tl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JeeqiqGBIzAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = pd.read_csv(\"drive/My Drive/Colab Notebooks/abs_summ/data/train.csv\")"
      ],
      "metadata": {
        "id": "4TXNlY_iI1iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.drop(['id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "E6-3E2iTI7FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.head()"
      ],
      "metadata": {
        "id": "1DDwIZiNI8zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.shape"
      ],
      "metadata": {
        "id": "pAzGoLpDJCrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = cnn['article']\n",
        "summary = cnn['highlights']"
      ],
      "metadata": {
        "id": "IGrXxBzwJH9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document[30], summary[30]"
      ],
      "metadata": {
        "id": "_X7amTz3JI32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # for decoder sequence\n",
        "# summary = summary.apply(lambda x: '<go> ' + x + ' <stop>')\n",
        "# summary.head()"
      ],
      "metadata": {
        "id": "CVNKR_N4JLPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since < and > from default tokens cannot be removed\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'"
      ],
      "metadata": {
        "id": "cnIm6y8kKGyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)"
      ],
      "metadata": {
        "id": "BkhMBvE_J_9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_tokenizer.fit_on_texts(document)\n",
        "summary_tokenizer.fit_on_texts(summary)"
      ],
      "metadata": {
        "id": "EpBPtpgrKDfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = document_tokenizer.texts_to_sequences(document)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "metadata": {
        "id": "JzrhpIV4KKIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.texts_to_sequences([\"This is a test\"])"
      ],
      "metadata": {
        "id": "EupEbrXaKNt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.sequences_to_texts([[54, 11, 6, 549]])"
      ],
      "metadata": {
        "id": "bs5MWD5mKQkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "# vocab_size\n",
        "encoder_vocab_size, decoder_vocab_size"
      ],
      "metadata": {
        "id": "jzYSoZXqKTCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_lengths = pd.Series([len(x) for x in document])\n",
        "summary_lengths = pd.Series([len(x) for x in summary])"
      ],
      "metadata": {
        "id": "Ujc1NcjZKY3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_lengths.describe()"
      ],
      "metadata": {
        "id": "5Pzmsn-CKbQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_lengths.describe()"
      ],
      "metadata": {
        "id": "YKKC4gbaKdUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(input_str, EOS=1):\n",
        "    inputs=summary_tokenizer.texts_to_sequences([input_str])\n",
        "    # Mark the end of the sentence with EOS\n",
        "    input_list=inputs[0]\n",
        "    input_list.append(EOS)\n",
        "    return input_list\n",
        "\n",
        "def detokenize(integers):\n",
        "    \"\"\"List of ints to str\"\"\"\n",
        "  \n",
        "    s = summary_tokenizer.sequences_to_texts(integers)\n",
        "    \n",
        "    return s[0]"
      ],
      "metadata": {
        "id": "h3OvsEsLKhLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize('This is a test')\n"
      ],
      "metadata": {
        "id": "ys4PNZsfMk3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detokenize([[54, 11, 6, 549,1]])"
      ],
      "metadata": {
        "id": "yUJ3HM9AP4bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow._api.v2.experimental.numpy import int32\n",
        "def create_tensor(t):\n",
        "    \"\"\"Create tensor from list of lists\"\"\"\n",
        "    # return tf.constant(t)\n",
        "    if isinstance(t[0][0],bool):\n",
        "      return tf.constant(t)\n",
        "    else:\n",
        "      return tf.constant(t,dtype=tf.float32)\n",
        "\n",
        "\n",
        "def display_tensor(t, name):\n",
        "    \"\"\"Display shape and tensor\"\"\"\n",
        "    print(f'{name} shape: {t.shape}\\n')\n",
        "    print(f'{t}\\n')"
      ],
      "metadata": {
        "id": "H0Bwuo6gV5g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# q=[[1., 0., 0.],\n",
        "#    [0., 1. ,0.]]\n",
        "# # x=create_tensor([[q,q],[q,q]])\n",
        "# # x\n",
        "# x=tf.concat([q, q], axis = -1)\n",
        "# y=create_tensor(x)\n",
        "# y"
      ],
      "metadata": {
        "id": "eO_QZhwtjoEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = create_tensor([[1, 0, 0], [0, 1, 0]])\n",
        "display_tensor(q, 'query')\n",
        "k = create_tensor([[1, 2, 3], [4, 5, 6]])\n",
        "display_tensor(k, 'key')\n",
        "v = create_tensor([[0, 1, 0], [1, 0, 1]])\n",
        "display_tensor(v, 'value')\n",
        "m = create_tensor([[0, 0], [-1e9, 0]])\n",
        "display_tensor(m, 'mask')\n",
        "\n",
        "# if isinstance(q[0][0], tf.float32):\n",
        "#   print(True)"
      ],
      "metadata": {
        "id": "RTIYCZx4V6ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(3)"
      ],
      "metadata": {
        "id": "qLdtdjVZX3ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()"
      ],
      "metadata": {
        "id": "eSSxdq01ZBpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_dot_k = np.dot(q,k.T) / np.sqrt(3)\n",
        "display_tensor(q_dot_k, 'query dot key')"
      ],
      "metadata": {
        "id": "XpsxZZIYXDy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked = q_dot_k + m\n",
        "display_tensor(masked, 'masked query dot key')"
      ],
      "metadata": {
        "id": "ZA3-MFaHZGy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_tensor(masked @ v, 'masked query dot key dot value')"
      ],
      "metadata": {
        "id": "HWOqUV58ZJ1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_with_batch = q[None,:]\n",
        "display_tensor(q_with_batch, 'query with batch dim')\n",
        "k_with_batch = k[None,:]\n",
        "display_tensor(k_with_batch, 'key with batch dim')\n",
        "v_with_batch = v[None,:]\n",
        "display_tensor(v_with_batch, 'value with batch dim')\n",
        "m_bool = create_tensor([[True, True], [False, True]])\n",
        "display_tensor(m_bool, 'boolean mask')"
      ],
      "metadata": {
        "id": "WZTHJHDfZNzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C1\n",
        "# GRADED FUNCTION: DotProductAttention\n",
        "def DotProductAttention(query, key, value, mask):\n",
        "    \"\"\"Dot product self-attention.\n",
        "    Args:\n",
        "        query (jax.interpreters.xla.DeviceArray): array of query representations with shape (L_q by d)\n",
        "        key (jax.interpreters.xla.DeviceArray): array of key representations with shape (L_k by d)\n",
        "        value (jax.interpreters.xla.DeviceArray): array of value representations with shape (L_k by d) where L_v = L_k\n",
        "        mask (jax.interpreters.xla.DeviceArray): attention-mask, gates attention with shape (L_q by L_k)\n",
        "\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: Self-attention array for q, k, v arrays. (L_q by L_k)\n",
        "    \"\"\"\n",
        "\n",
        "    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"Embedding dimensions of q, k, v aren't all the same\"\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
        "    # Save depth/dimension of the query embedding for scaling down the dot product\n",
        "    depth = query.shape[-1]\n",
        "\n",
        "    # Calculate scaled query key dot product according to formula above\n",
        "    dots = tf.linalg.matmul(query, tf.experimental.numpy.swapaxes(key, -1, -2)) / np.sqrt(depth)\n",
        "    \n",
        "    # Apply the mask\n",
        "    if mask is not None: # You do not need to replace the 'None' on this line\n",
        "        dots = tf.where(mask, dots, tf.experimental.numpy.full_like(dots, -1e9))\n",
        "    \n",
        "    # Softmax formula implementation\n",
        "    # Use trax.fastmath.logsumexp of masked_qkT to avoid underflow by division by large numbers\n",
        "    # Note: softmax = None\n",
        "    logsumexp = tf.math.reduce_logsumexp(dots, axis=-1, keepdims=True)\n",
        "\n",
        "    # Take exponential of dots minus logsumexp to get softmax\n",
        "    # Use jnp.exp()\n",
        "    dots = tf.math.exp(dots - logsumexp)\n",
        "    \n",
        "    # Multiply dots by value to get self-attention\n",
        "    # Use jnp.matmul()\n",
        "    attention = tf.linalg.matmul(dots, value)\n",
        "\n",
        "    ## END CODE HERE ###\n",
        "    \n",
        "    return attention"
      ],
      "metadata": {
        "id": "amfmZ8O1ZQeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DotProductAttention(q_with_batch, k_with_batch, v_with_batch, m_bool)"
      ],
      "metadata": {
        "id": "TeK4xP8WZTpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d = create_tensor(q)\n",
        "display_tensor(tensor2d, 'query matrix (2D tensor)')\n",
        "\n",
        "tensor4d2b = create_tensor([[q, q], [q, q]])\n",
        "display_tensor(tensor4d2b, 'batch of two (multi-head) collections of query matrices (4D tensor)')\n",
        "\n",
        "tensor3dc = create_tensor([tf.concat([q, q], axis = -1)])\n",
        "display_tensor(tensor3dc, 'one batch of concatenated heads of query matrices (3d tensor)')\n",
        "\n",
        "tensor3dc3b = create_tensor([tf.concat([q, q], axis = -1), tf.concat([q, q], axis = -1), tf.concat([q, q], axis = -1)])\n",
        "display_tensor(tensor3dc3b, 'three batches of concatenated heads of query matrices (3d tensor)')"
      ],
      "metadata": {
        "id": "metiYpwtlUJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C2\n",
        "# GRADED FUNCTION: compute_attention_heads_closure\n",
        "def compute_attention_heads_closure(n_heads, d_head):\n",
        "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
        "    Args:\n",
        "        d_head (int):  dimensionality of heads\n",
        "        n_heads (int): number of attention heads\n",
        "    Returns:\n",
        "        function: compute_attention_heads function\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_attention_heads(x):\n",
        "        \"\"\" Compute the attention heads.\n",
        "        Args:\n",
        "            x (jax.interpreters.xla.DeviceArray): tensor with shape (n_batch, seqlen, n_heads X d_head).\n",
        "        Returns:\n",
        "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (n_batch X n_heads, seqlen, d_head).\n",
        "        \"\"\"\n",
        "        ### START CODE HERE ###\n",
        "        # (REPLACE INSTANCES OF 'None' WITH YOUR CODE)\n",
        "        \n",
        "        # Size of the x's batch dimension\n",
        "        batch_size = x.shape[0]\n",
        "        # Length of the sequence\n",
        "        # Should be size of x's first dimension without counting the batch dim\n",
        "        seqlen = x.shape[1]\n",
        "        # Reshape x using jnp.reshape()\n",
        "        # n_batch, seqlen, n_heads*d_head -> n_batch, seqlen, n_heads, d_head\n",
        "        x = tf.reshape(x, (batch_size, seqlen, n_heads, d_head))\n",
        "        # Transpose x using jnp.transpose()\n",
        "        # n_batch, seqlen, n_heads, d_head -> n_batch, n_heads, seqlen, d_head\n",
        "        # Note that the values within the tuple are the indexes of the dimensions of x and you must rearrange them\n",
        "        x = tf.transpose(x, (0, 2, 1, 3))\n",
        "        # Reshape x using jnp.reshape()\n",
        "        # n_batch, n_heads, seqlen, d_head -> n_batch*n_heads, seqlen, d_head\n",
        "        x = tf.reshape(x, (-1, seqlen, d_head))\n",
        "        \n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        return x\n",
        "    return compute_attention_heads"
      ],
      "metadata": {
        "id": "NGYf3e4cmzTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_tensor(tensor3dc3b, \"input tensor\")\n",
        "result_cah = compute_attention_heads_closure(2,3)(tensor3dc3b)\n",
        "display_tensor(result_cah, \"output tensor\")"
      ],
      "metadata": {
        "id": "ZIu5nel4nKqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # UNQ_C6\n",
        "# # GRADED FUNCTION: DecoderBlock\n",
        "# def DecoderBlock(d_model, d_ff, n_heads,\n",
        "#                  dropout, mode, ff_activation):\n",
        "#     \"\"\"Returns a list of layers that implements a Transformer decoder block.\n",
        "\n",
        "#     The input is an activation tensor.\n",
        "\n",
        "#     Args:\n",
        "#         d_model (int):  depth of embedding.\n",
        "#         d_ff (int): depth of feed-forward layer.\n",
        "#         n_heads (int): number of attention heads.\n",
        "#         dropout (float): dropout rate (how much to drop out).\n",
        "#         mode (str): 'train' or 'eval'.\n",
        "#         ff_activation (function): the non-linearity in feed-forward layer.\n",
        "\n",
        "#     Returns:\n",
        "#         list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.\n",
        "#     \"\"\"\n",
        "    \n",
        "#     ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
        "    \n",
        "#      # Create masked multi-head attention block using CausalAttention function\n",
        "#     causal_attention = CausalAttention( \n",
        "#                         d_model,\n",
        "#                         n_heads=n_heads,\n",
        "#                         mode=mode\n",
        "#                         )\n",
        "\n",
        "#     # Create feed-forward block (list) with two dense layers with dropout and input normalized\n",
        "#     feed_forward = [ \n",
        "#         # Normalize layer inputs\n",
        "#         tl.LayerNorm(),\n",
        "#         # Add first feed forward (dense) layer (don't forget to set the correct value for n_units)\n",
        "#         tl.Dense(d_ff),\n",
        "#         # Add activation function passed in as a parameter (you need to call it!)\n",
        "#         ff_activation(), # Generally ReLU\n",
        "#         # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
        "#         tl.Dropout(rate=dropout, mode=mode),\n",
        "#         # Add second feed forward layer (don't forget to set the correct value for n_units)\n",
        "#         tl.Dense(d_model),\n",
        "#         # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
        "#         tl.Dropout(rate=dropout, mode=mode)\n",
        "#     ]\n",
        "\n",
        "#     # Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks\n",
        "#     return [\n",
        "#       tl.Residual(\n",
        "#           # Normalize layer input\n",
        "#           tl.LayerNorm(),\n",
        "#           # Add causal attention block previously defined (without parentheses)\n",
        "#           causal_attention,\n",
        "#           # Add dropout with rate and mode specified\n",
        "#           tl.Dropout(rate=dropout, mode=mode)\n",
        "#         ),\n",
        "#       tl.Residual(\n",
        "#           # Add feed forward block (without parentheses)\n",
        "#           feed_forward\n",
        "#         ),\n",
        "#       ]\n",
        "#     ### END CODE HERE ###"
      ],
      "metadata": {
        "id": "DU-U4dS7Udyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Take a look at the decoder block\n",
        "# print(DecoderBlock(d_model=512, d_ff=2048, n_heads=8, dropout=0.1, mode='train', ff_activation=tl.Relu))"
      ],
      "metadata": {
        "id": "vGvHoFQ0UzSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}