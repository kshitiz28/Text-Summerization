{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-small and revision d769bba (https://huggingface.co/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading: 100%|██████████| 1.20k/1.20k [00:00<?, ?B/s]\n",
      "c:\\Users\\Kshitiz\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:125: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kshitiz\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|██████████| 242M/242M [00:24<00:00, 9.72MB/s] \n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Downloading: 100%|██████████| 792k/792k [00:01<00:00, 650kB/s]  \n",
      "Downloading: 100%|██████████| 1.39M/1.39M [00:01<00:00, 956kB/s] \n",
      "c:\\Users\\Kshitiz\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "summarizer=pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "This study aimed to assess the overall scenario of COVID-19 during the lockdown (positive cases, RT-PCR test performed, recoveries, total active and deaths cases including case fatality ratio) including spatial distribution of the cases, government measures to manage the pandemic; and impacts on public health, socio-economy, and education\n",
    " The strict lockdown was enforced to limit the spread of COVID-19 in countries such as Italy, Spain, France, the UK after the steady rise in cases whereas Nepal introduced lockdown during the early phase of the pandemic (10)\n",
    " Finally, we offer helpful suggestions to address the challenges brought by the impact of COVID-19\n",
    " The R0 value of the COVID-19 outbreak was not available for Nepal when the government was preparing for the lockdown\n",
    "Coronavirus disease (COVID-19) outbreak originating from Wuhan, China in late 2019 has spread worldwide claiming more than 2\n",
    " The Government of Nepal issued a nationwide lockdown from 24 March to 21 July 2020, prohibiting domestic and international travels, closure of border and non-essential services in the first stage, which was later eased on 11 June 2020\n",
    "Several modeling studies have been conducted during the early phases of the outbreak to predict the epidemic and effectiveness of multiple population-wide strategies, including lockdown, social distancing, quarantine, testing and contact tracing, and media-related awareness among others to mitigate the spread of COVID-19 (3–9)\n",
    " There were only two confirmed cases from 610 Reverse Transcription Polymerase Chain Reaction (RT-PCR) tests and no fatalities before lockdown (12)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'study aimed to assess the overall scenario of COVID-19 during the lockdown (positive cases, RT-PCR test performed, recoveries, total active and deaths cases including case fatality ratio) and impacts on public health, socio-economy, and education . strict lockdown was enforced to limit the spread of the outbreak in countries such as Italy, Spain, France, the UK .'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(article,max_length=150,min_length=30,do_sample=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b2e37b41e001ca1129809f0c88577fc595d7813eddff4f14ec8461c07872299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
